{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20cc39b3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mlflow import MlflowClient\n",
    "from pprint import pprint\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd00304d",
   "metadata": {},
   "source": [
    "### Initializing the MLflow Client\n",
    "\n",
    "In step 1 of the tutorial, we started an MLflow Tracking Server with:\n",
    "\n",
    "*host* = **127.0.0.1** \n",
    "\n",
    "*port* = **8080**\n",
    "\n",
    "Let's connect to that uri with the MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac741989",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MlflowClient(tracking_uri=\"http://127.0.0.1:8080\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6129354a",
   "metadata": {},
   "source": [
    "#### Search Experiments with the MLflow Client API\n",
    "\n",
    "Let's take a look at the Default Experiment that is created for us.\n",
    "\n",
    "This safe 'fallback' experiment will store Runs that we create if we don't specify a \n",
    "new experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f208d9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Search experiments without providing query terms behaves effectively as a 'list' action\n",
    "\n",
    "all_experiments = client.search_experiments()\n",
    "\n",
    "print(all_experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b1e1914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lifecycle_stage': 'active', 'name': 'Default'}\n"
     ]
    }
   ],
   "source": [
    "# Extract the experiment name and lifecycle_stage\n",
    "\n",
    "default_experiment = [\n",
    "    {\"name\": experiment.name, \"lifecycle_stage\": experiment.lifecycle_stage}\n",
    "    for experiment in all_experiments\n",
    "    if experiment.name == \"Default\"\n",
    "][0]\n",
    "\n",
    "pprint(default_experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d74e180b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Extract the experiment name and lifecycle_stage\n",
    "\n",
    "default_experiment = [\n",
    "    {\"name\": experiment.name, \"lifecycle_stage\": experiment.lifecycle_stage}\n",
    "    for experiment in all_experiments\n",
    "    if experiment.name == \"Apple_Models\"\n",
    "]#[0]\n",
    "\n",
    "pprint(default_experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c37836",
   "metadata": {},
   "source": [
    "### Creating a new Experiment\n",
    "\n",
    "In this section, we'll:\n",
    "\n",
    "* create a new MLflow Experiment\n",
    "* apply metadata in the form of Experiment Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b07c851f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RestException",
     "evalue": "RESOURCE_ALREADY_EXISTS: Experiment 'Apple_Models' already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRestException\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 14\u001b[0m\n\u001b[1;32m      1\u001b[0m experiment_description \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is the grocery forecasting project. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis experiment contains the produce models for apples.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      6\u001b[0m experiment_tags \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproject_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrocery-forecasting\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore_dept\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproduce\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlflow.note.content\u001b[39m\u001b[38;5;124m\"\u001b[39m: experiment_description,\n\u001b[1;32m     12\u001b[0m }\n\u001b[0;32m---> 14\u001b[0m produce_apples_experiment \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mcreate_experiment(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mApple_Models\u001b[39m\u001b[38;5;124m\"\u001b[39m, tags\u001b[38;5;241m=\u001b[39mexperiment_tags)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/mlflow/tracking/client.py:557\u001b[0m, in \u001b[0;36mMlflowClient.create_experiment\u001b[0;34m(self, name, artifact_location, tags)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_experiment\u001b[39m(\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    511\u001b[0m     name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    512\u001b[0m     artifact_location: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    513\u001b[0m     tags: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    514\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    515\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create an experiment.\u001b[39;00m\n\u001b[1;32m    516\u001b[0m \n\u001b[1;32m    517\u001b[0m \u001b[38;5;124;03m    :param name: The experiment name. Must be unique.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;124;03m        Lifecycle_stage: active\u001b[39;00m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 557\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tracking_client\u001b[38;5;241m.\u001b[39mcreate_experiment(name, artifact_location, tags)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/mlflow/tracking/_tracking_service/client.py:236\u001b[0m, in \u001b[0;36mTrackingServiceClient.create_experiment\u001b[0;34m(self, name, artifact_location, tags)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create an experiment.\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \n\u001b[1;32m    227\u001b[0m \u001b[38;5;124;03m:param name: The experiment name. Must be unique.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;124;03m:return: Integer ID of the created experiment.\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    234\u001b[0m _validate_experiment_artifact_location(artifact_location)\n\u001b[0;32m--> 236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore\u001b[38;5;241m.\u001b[39mcreate_experiment(\n\u001b[1;32m    237\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m    238\u001b[0m     artifact_location\u001b[38;5;241m=\u001b[39martifact_location,\n\u001b[1;32m    239\u001b[0m     tags\u001b[38;5;241m=\u001b[39m[ExperimentTag(key, value) \u001b[38;5;28;01mfor\u001b[39;00m (key, value) \u001b[38;5;129;01min\u001b[39;00m tags\u001b[38;5;241m.\u001b[39mitems()] \u001b[38;5;28;01mif\u001b[39;00m tags \u001b[38;5;28;01melse\u001b[39;00m [],\n\u001b[1;32m    240\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/mlflow/store/tracking/rest_store.py:98\u001b[0m, in \u001b[0;36mRestStore.create_experiment\u001b[0;34m(self, name, artifact_location, tags)\u001b[0m\n\u001b[1;32m     94\u001b[0m tag_protos \u001b[38;5;241m=\u001b[39m [tag\u001b[38;5;241m.\u001b[39mto_proto() \u001b[38;5;28;01mfor\u001b[39;00m tag \u001b[38;5;129;01min\u001b[39;00m tags] \u001b[38;5;28;01mif\u001b[39;00m tags \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m     95\u001b[0m req_body \u001b[38;5;241m=\u001b[39m message_to_json(\n\u001b[1;32m     96\u001b[0m     CreateExperiment(name\u001b[38;5;241m=\u001b[39mname, artifact_location\u001b[38;5;241m=\u001b[39martifact_location, tags\u001b[38;5;241m=\u001b[39mtag_protos)\n\u001b[1;32m     97\u001b[0m )\n\u001b[0;32m---> 98\u001b[0m response_proto \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_endpoint(CreateExperiment, req_body)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response_proto\u001b[38;5;241m.\u001b[39mexperiment_id\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/mlflow/store/tracking/rest_store.py:59\u001b[0m, in \u001b[0;36mRestStore._call_endpoint\u001b[0;34m(self, api, json_body)\u001b[0m\n\u001b[1;32m     57\u001b[0m endpoint, method \u001b[38;5;241m=\u001b[39m _METHOD_TO_INFO[api]\n\u001b[1;32m     58\u001b[0m response_proto \u001b[38;5;241m=\u001b[39m api\u001b[38;5;241m.\u001b[39mResponse()\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m call_endpoint(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_host_creds(), endpoint, method, json_body, response_proto)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/mlflow/utils/rest_utils.py:203\u001b[0m, in \u001b[0;36mcall_endpoint\u001b[0;34m(host_creds, endpoint, method, json_body, response_proto, extra_headers)\u001b[0m\n\u001b[1;32m    201\u001b[0m     call_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m json_body\n\u001b[1;32m    202\u001b[0m     response \u001b[38;5;241m=\u001b[39m http_request(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcall_kwargs)\n\u001b[0;32m--> 203\u001b[0m response \u001b[38;5;241m=\u001b[39m verify_rest_response(response, endpoint)\n\u001b[1;32m    204\u001b[0m js_dict \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m    205\u001b[0m parse_dict(js_dict\u001b[38;5;241m=\u001b[39mjs_dict, message\u001b[38;5;241m=\u001b[39mresponse_proto)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/mlflow/utils/rest_utils.py:135\u001b[0m, in \u001b[0;36mverify_rest_response\u001b[0;34m(response, endpoint)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _can_parse_as_json_object(response\u001b[38;5;241m.\u001b[39mtext):\n\u001b[0;32m--> 135\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m RestException(json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mtext))\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m         base_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    138\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI request to endpoint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    139\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailed with error code \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m != 200\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    140\u001b[0m         )\n",
      "\u001b[0;31mRestException\u001b[0m: RESOURCE_ALREADY_EXISTS: Experiment 'Apple_Models' already exists."
     ]
    }
   ],
   "source": [
    "experiment_description = (\n",
    "    \"This is the grocery forecasting project. \"\n",
    "    \"This experiment contains the produce models for apples.\"\n",
    ")\n",
    "\n",
    "experiment_tags = {\n",
    "    \"project_name\": \"grocery-forecasting\",\n",
    "    \"store_dept\": \"produce\",\n",
    "    \"team\": \"stores-ml\",\n",
    "    \"project_quarter\": \"Q3-2023\",\n",
    "    \"mlflow.note.content\": experiment_description,\n",
    "}\n",
    "\n",
    "produce_apples_experiment = client.create_experiment(name=\"Apple_Models\", tags=experiment_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_description = (\n",
    "    \"This is the test for composed tensor data.\"\n",
    ")\n",
    "\n",
    "experiment_tags = {\n",
    "    \"project_name\": \"data test\",\n",
    "    \"mlflow.note.content\": experiment_description,\n",
    "}\n",
    "\n",
    "test_experiment = client.create_experiment(name=\"Test\", tags=experiment_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3858e72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "<class 'mlflow.store.entities.paged_list.PagedList'>\n",
      "<class 'mlflow.entities.experiment.Experiment'>\n",
      "[<Experiment: artifact_location='mlflow-artifacts:/275732136076985190', creation_time=1702367152826, experiment_id='275732136076985190', last_update_time=1702367152826, lifecycle_stage='active', name='Test', tags={'mlflow.note.content': 'This is the test for composed tensor data.',\n",
      " 'project_name': 'data test'}>]\n",
      "<Experiment: artifact_location='mlflow-artifacts:/275732136076985190', creation_time=1702367152826, experiment_id='275732136076985190', last_update_time=1702367152826, lifecycle_stage='active', name='Test', tags={'mlflow.note.content': 'This is the test for composed tensor data.',\n",
      " 'project_name': 'data test'}>\n"
     ]
    }
   ],
   "source": [
    "# Use search_experiments() to search on the project_name tag key\n",
    "\n",
    "test_experiment = client.search_experiments(\n",
    "    filter_string=\"tags.`project_name` = 'data test'\"\n",
    ")\n",
    "print(len(test_experiment))\n",
    "print(type(test_experiment))\n",
    "print(type(test_experiment[0]))\n",
    "\n",
    "pprint(test_experiment)\n",
    "pprint(test_experiment[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "181a5545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the test for composed tensor data.\n"
     ]
    }
   ],
   "source": [
    "# Access individual tag data\n",
    "\n",
    "print(test_experiment[0].tags[\"mlflow.note.content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c66551",
   "metadata": {},
   "source": [
    "### Running our first model training\n",
    "\n",
    "In this section, we'll:\n",
    "\n",
    "* create a synthetic data set that is relevant to a simple demand forecasting task\n",
    "* start an MLflow run\n",
    "* log metrics, parameters, and tags to the run\n",
    "* save the model to the run\n",
    "* register the model during model logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faffa16",
   "metadata": {},
   "source": [
    "#### Synthetic data generator for demand of apples\n",
    "\n",
    "Keep in mind that this is purely for demonstration purposes. \n",
    "\n",
    "The demand value is purely artificial and is deliberately covariant with the features. This is not a particularly realistic real-world scenario (if it were, we wouldn't need Data Scientists!). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2268a1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "def generate_apple_sales_data_with_promo_adjustment(base_demand: int = 1000, n_rows: int = 5000):\n",
    "    \"\"\"\n",
    "    Generates a synthetic dataset for predicting apple sales demand with seasonality and inflation.\n",
    "\n",
    "    This function creates a pandas DataFrame with features relevant to apple sales.\n",
    "    The features include date, average_temperature, rainfall, weekend flag, holiday flag,\n",
    "    promotional flag, price_per_kg, and the previous day's demand. The target variable,\n",
    "    'demand', is generated based on a combination of these features with some added noise.\n",
    "\n",
    "    Args:\n",
    "        base_demand (int, optional): Base demand for apples. Defaults to 1000.\n",
    "        n_rows (int, optional): Number of rows (days) of data to generate. Defaults to 5000.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with features and target variable for apple sales prediction.\n",
    "\n",
    "    Example:\n",
    "        >>> df = generate_apple_sales_data_with_seasonality(base_demand=1200, n_rows=6000)\n",
    "        >>> df.head()\n",
    "    \"\"\"\n",
    "\n",
    "    # Set seed for reproducibility\n",
    "    np.random.seed(9999)\n",
    "\n",
    "    # Create date range\n",
    "    dates = [datetime.now() - timedelta(days=i) for i in range(n_rows)]\n",
    "    dates.reverse()\n",
    "\n",
    "    # Generate features\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"date\": dates,\n",
    "            \"average_temperature\": np.random.uniform(10, 35, n_rows),\n",
    "            \"rainfall\": np.random.exponential(5, n_rows),\n",
    "            \"weekend\": [(date.weekday() >= 5) * 1 for date in dates],\n",
    "            \"holiday\": np.random.choice([0, 1], n_rows, p=[0.97, 0.03]),\n",
    "            \"price_per_kg\": np.random.uniform(0.5, 3, n_rows),\n",
    "            \"month\": [date.month for date in dates],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Introduce inflation over time (years)\n",
    "    df[\"inflation_multiplier\"] = 1 + (df[\"date\"].dt.year - df[\"date\"].dt.year.min()) * 0.03\n",
    "\n",
    "    # Incorporate seasonality due to apple harvests\n",
    "    df[\"harvest_effect\"] = np.sin(2 * np.pi * (df[\"month\"] - 3) / 12) + np.sin(\n",
    "        2 * np.pi * (df[\"month\"] - 9) / 12\n",
    "    )\n",
    "\n",
    "    # Modify the price_per_kg based on harvest effect\n",
    "    df[\"price_per_kg\"] = df[\"price_per_kg\"] - df[\"harvest_effect\"] * 0.5\n",
    "\n",
    "    # Adjust promo periods to coincide with periods lagging peak harvest by 1 month\n",
    "    peak_months = [4, 10]  # months following the peak availability\n",
    "    df[\"promo\"] = np.where(\n",
    "        df[\"month\"].isin(peak_months),\n",
    "        1,\n",
    "        np.random.choice([0, 1], n_rows, p=[0.85, 0.15]),\n",
    "    )\n",
    "\n",
    "    # Generate target variable based on features\n",
    "    base_price_effect = -df[\"price_per_kg\"] * 50\n",
    "    seasonality_effect = df[\"harvest_effect\"] * 50\n",
    "    promo_effect = df[\"promo\"] * 200\n",
    "\n",
    "    df[\"demand\"] = (\n",
    "        base_demand\n",
    "        + base_price_effect\n",
    "        + seasonality_effect\n",
    "        + promo_effect\n",
    "        + df[\"weekend\"] * 300\n",
    "        + np.random.normal(0, 50, n_rows)\n",
    "    ) * df[\n",
    "        \"inflation_multiplier\"\n",
    "    ]  # adding random noise\n",
    "\n",
    "    # Add previous day's demand\n",
    "    df[\"previous_days_demand\"] = df[\"demand\"].shift(1)\n",
    "    df[\"previous_days_demand\"].fillna(method=\"bfill\", inplace=True)  # fill the first row\n",
    "\n",
    "    # Drop temporary columns\n",
    "    df.drop(columns=[\"inflation_multiplier\", \"harvest_effect\", \"month\"], inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2924d135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>average_temperature</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>weekend</th>\n",
       "      <th>holiday</th>\n",
       "      <th>price_per_kg</th>\n",
       "      <th>promo</th>\n",
       "      <th>demand</th>\n",
       "      <th>previous_days_demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>2023-10-28 09:53:58.549478</td>\n",
       "      <td>34.130183</td>\n",
       "      <td>1.454065</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.449177</td>\n",
       "      <td>1</td>\n",
       "      <td>1501.802447</td>\n",
       "      <td>1213.085782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>2023-10-29 09:53:58.549476</td>\n",
       "      <td>32.353643</td>\n",
       "      <td>9.462859</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.856503</td>\n",
       "      <td>1</td>\n",
       "      <td>1348.951553</td>\n",
       "      <td>1501.802447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>2023-10-30 09:53:58.549473</td>\n",
       "      <td>18.816833</td>\n",
       "      <td>0.391470</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.326429</td>\n",
       "      <td>1</td>\n",
       "      <td>1175.352029</td>\n",
       "      <td>1348.951553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>2023-10-31 09:53:58.549471</td>\n",
       "      <td>34.533012</td>\n",
       "      <td>2.120477</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.970131</td>\n",
       "      <td>1</td>\n",
       "      <td>1251.385504</td>\n",
       "      <td>1175.352029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>2023-11-01 09:53:58.549469</td>\n",
       "      <td>23.057202</td>\n",
       "      <td>2.365705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.049931</td>\n",
       "      <td>0</td>\n",
       "      <td>991.427049</td>\n",
       "      <td>1251.385504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>2023-11-02 09:53:58.549467</td>\n",
       "      <td>34.810165</td>\n",
       "      <td>3.089005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.035149</td>\n",
       "      <td>0</td>\n",
       "      <td>974.971149</td>\n",
       "      <td>991.427049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>2023-11-03 09:53:58.549465</td>\n",
       "      <td>29.208905</td>\n",
       "      <td>3.673292</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.518098</td>\n",
       "      <td>0</td>\n",
       "      <td>1056.249547</td>\n",
       "      <td>974.971149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>2023-11-04 09:53:58.549462</td>\n",
       "      <td>16.428676</td>\n",
       "      <td>4.077782</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.268979</td>\n",
       "      <td>0</td>\n",
       "      <td>1381.118915</td>\n",
       "      <td>1056.249547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>2023-11-05 09:53:58.549460</td>\n",
       "      <td>32.067512</td>\n",
       "      <td>2.734454</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.762317</td>\n",
       "      <td>0</td>\n",
       "      <td>1358.492007</td>\n",
       "      <td>1381.118915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>2023-11-06 09:53:58.549458</td>\n",
       "      <td>31.938203</td>\n",
       "      <td>13.883486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.153301</td>\n",
       "      <td>0</td>\n",
       "      <td>967.040470</td>\n",
       "      <td>1358.492007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>2023-11-07 09:53:58.549456</td>\n",
       "      <td>18.024055</td>\n",
       "      <td>7.544061</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.610703</td>\n",
       "      <td>0</td>\n",
       "      <td>1048.644564</td>\n",
       "      <td>967.040470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>2023-11-08 09:53:58.549453</td>\n",
       "      <td>20.681067</td>\n",
       "      <td>18.820490</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.533488</td>\n",
       "      <td>0</td>\n",
       "      <td>973.934924</td>\n",
       "      <td>1048.644564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>2023-11-09 09:53:58.549448</td>\n",
       "      <td>16.010132</td>\n",
       "      <td>7.705941</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.632498</td>\n",
       "      <td>1</td>\n",
       "      <td>1188.291256</td>\n",
       "      <td>973.934924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>2023-11-10 09:53:58.549443</td>\n",
       "      <td>18.766455</td>\n",
       "      <td>6.274840</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.806554</td>\n",
       "      <td>0</td>\n",
       "      <td>930.089438</td>\n",
       "      <td>1188.291256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>2023-11-11 09:53:58.549441</td>\n",
       "      <td>27.948793</td>\n",
       "      <td>23.705246</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.829464</td>\n",
       "      <td>0</td>\n",
       "      <td>1378.576311</td>\n",
       "      <td>930.089438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2023-11-12 09:53:58.549438</td>\n",
       "      <td>28.661072</td>\n",
       "      <td>10.329865</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.290591</td>\n",
       "      <td>0</td>\n",
       "      <td>1228.690776</td>\n",
       "      <td>1378.576311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2023-11-13 09:53:58.549436</td>\n",
       "      <td>10.821693</td>\n",
       "      <td>3.575645</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.897473</td>\n",
       "      <td>0</td>\n",
       "      <td>988.363801</td>\n",
       "      <td>1228.690776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2023-11-14 09:53:58.549434</td>\n",
       "      <td>21.108560</td>\n",
       "      <td>6.221089</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.093864</td>\n",
       "      <td>0</td>\n",
       "      <td>1034.422372</td>\n",
       "      <td>988.363801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2023-11-15 09:53:58.549430</td>\n",
       "      <td>29.451301</td>\n",
       "      <td>5.021463</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.493085</td>\n",
       "      <td>0</td>\n",
       "      <td>952.303256</td>\n",
       "      <td>1034.422372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2023-11-16 09:53:58.549416</td>\n",
       "      <td>19.261458</td>\n",
       "      <td>0.438381</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.610422</td>\n",
       "      <td>0</td>\n",
       "      <td>855.963448</td>\n",
       "      <td>952.303256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          date  average_temperature   rainfall  weekend  \\\n",
       "980 2023-10-28 09:53:58.549478            34.130183   1.454065        1   \n",
       "981 2023-10-29 09:53:58.549476            32.353643   9.462859        1   \n",
       "982 2023-10-30 09:53:58.549473            18.816833   0.391470        0   \n",
       "983 2023-10-31 09:53:58.549471            34.533012   2.120477        0   \n",
       "984 2023-11-01 09:53:58.549469            23.057202   2.365705        0   \n",
       "985 2023-11-02 09:53:58.549467            34.810165   3.089005        0   \n",
       "986 2023-11-03 09:53:58.549465            29.208905   3.673292        0   \n",
       "987 2023-11-04 09:53:58.549462            16.428676   4.077782        1   \n",
       "988 2023-11-05 09:53:58.549460            32.067512   2.734454        1   \n",
       "989 2023-11-06 09:53:58.549458            31.938203  13.883486        0   \n",
       "990 2023-11-07 09:53:58.549456            18.024055   7.544061        0   \n",
       "991 2023-11-08 09:53:58.549453            20.681067  18.820490        0   \n",
       "992 2023-11-09 09:53:58.549448            16.010132   7.705941        0   \n",
       "993 2023-11-10 09:53:58.549443            18.766455   6.274840        0   \n",
       "994 2023-11-11 09:53:58.549441            27.948793  23.705246        1   \n",
       "995 2023-11-12 09:53:58.549438            28.661072  10.329865        1   \n",
       "996 2023-11-13 09:53:58.549436            10.821693   3.575645        0   \n",
       "997 2023-11-14 09:53:58.549434            21.108560   6.221089        0   \n",
       "998 2023-11-15 09:53:58.549430            29.451301   5.021463        0   \n",
       "999 2023-11-16 09:53:58.549416            19.261458   0.438381        0   \n",
       "\n",
       "     holiday  price_per_kg  promo       demand  previous_days_demand  \n",
       "980        0      1.449177      1  1501.802447           1213.085782  \n",
       "981        0      2.856503      1  1348.951553           1501.802447  \n",
       "982        0      1.326429      1  1175.352029           1348.951553  \n",
       "983        0      0.970131      1  1251.385504           1175.352029  \n",
       "984        0      1.049931      0   991.427049           1251.385504  \n",
       "985        0      2.035149      0   974.971149            991.427049  \n",
       "986        0      2.518098      0  1056.249547            974.971149  \n",
       "987        0      1.268979      0  1381.118915           1056.249547  \n",
       "988        0      0.762317      0  1358.492007           1381.118915  \n",
       "989        0      1.153301      0   967.040470           1358.492007  \n",
       "990        0      0.610703      0  1048.644564            967.040470  \n",
       "991        0      1.533488      0   973.934924           1048.644564  \n",
       "992        0      1.632498      1  1188.291256            973.934924  \n",
       "993        0      2.806554      0   930.089438           1188.291256  \n",
       "994        0      0.829464      0  1378.576311            930.089438  \n",
       "995        0      2.290591      0  1228.690776           1378.576311  \n",
       "996        0      0.897473      0   988.363801           1228.690776  \n",
       "997        0      1.093864      0  1034.422372            988.363801  \n",
       "998        0      2.493085      0   952.303256           1034.422372  \n",
       "999        0      2.610422      0   855.963448            952.303256  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the dataset!\n",
    "\n",
    "data = generate_apple_sales_data_with_promo_adjustment(base_demand=1_000, n_rows=1_000)\n",
    "\n",
    "data[-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e076a312",
   "metadata": {},
   "source": [
    "### Train and log the model\n",
    "\n",
    "We're now ready to import our model class and train a ``RandomForestRegressor``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e354900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# Use the fluent API to set the tracking uri and the active experiment\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "# Sets the current active experiment to the \"Apple_Models\" experiment and returns the Experiment metadata\n",
    "apple_experiment = mlflow.set_experiment(\"Test\")\n",
    "\n",
    "# Define a run name for this iteration of training.\n",
    "# If this is not set, a unique name will be auto-generated for your run.\n",
    "run_name = \"composed_tensor_test\"\n",
    "\n",
    "# Define an artifact path that the model will be saved to.\n",
    "artifact_path = \"model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mlflow-artifacts:/295829569244001181'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_experiment.artifact_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'mlflow-artifacts:/295829569244001181/test.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/jy_zhang/code/pycode/mlflow_logging-first-model.ipynb 单元格 20\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jy_zhang/code/pycode/mlflow_logging-first-model.ipynb#X40sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(apple_experiment\u001b[39m.\u001b[39martifact_location\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/test.txt\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jy_zhang/code/pycode/mlflow_logging-first-model.ipynb#X40sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     file\u001b[39m.\u001b[39mwrite(\u001b[39m'\u001b[39m\u001b[39mtest success.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/env_a/lib/python3.11/site-packages/IPython/core/interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    280\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    281\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m     )\n\u001b[0;32m--> 286\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'mlflow-artifacts:/295829569244001181/test.txt'"
     ]
    }
   ],
   "source": [
    "with open(apple_experiment.artifact_location+'/test.txt','w') as file:\n",
    "    file.write('test success.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow-artifacts:/295829569244001181/c1a37cd5ceb44c999fd70318edf5b41f/artifacts/model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "sd = torch.load('../pytorch_model.bin')\n",
    "\n",
    "run_name = \"composed_tensor_test_1\"\n",
    "# Initiate the MLflow run context\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    # Log the parameters used for the model fit\n",
    "    # mlflow.log_params(params)\n",
    "    #print(run.info)\n",
    "    # Log the error metrics that were calculated during validation\n",
    "    # mlflow.log_metrics(metrics)\n",
    "\n",
    "    # Log an instance of the trained model for later use\n",
    "    mlflow.pytorch.log_state_dict(state_dict = sd, artifact_path = 'model')\n",
    "    state_dict_uri = mlflow.get_artifact_uri(artifact_path)\n",
    "    mlflow.log_artifact('../pytorch_model.txt')\n",
    "print(state_dict_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80e4cf35a26b41b6b0203da292600e05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "state_dict = mlflow.pytorch.load_state_dict(state_dict_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "424"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('http://127.0.0.1:5000',\n",
       " 'mlflow-artifacts:/295829569244001181/7fc1cd52475f46d68302167a1e0f45a7/artifacts')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.tracking.get_tracking_uri(), mlflow.get_artifact_uri(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# Use the fluent API to set the tracking uri and the active experiment\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "\n",
    "# Sets the current active experiment to the \"Apple_Models\" experiment and returns the Experiment metadata\n",
    "test_experiment = mlflow.set_experiment(\"Apple_Models\")\n",
    "\n",
    "# Define a run name for this iteration of training.\n",
    "# If this is not set, a unique name will be auto-generated for your run.\n",
    "run_name = \"apples_rf_test\"\n",
    "\n",
    "# Define an artifact path that the model will be saved to.\n",
    "artifact_path = \"rf_apples\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae02e54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/11/16 10:13:07 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh()\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial warning can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|none|n|0: for no warning or exception\n",
      "    - warn|w|warning|1: for a printed warning\n",
      "    - error|e|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n",
      "/home/jy_zhang/anaconda3/lib/python3.11/site-packages/mlflow/models/signature.py:335: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  input_schema = _infer_schema(input_ex)\n",
      "/home/jy_zhang/anaconda3/lib/python3.11/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "# Split the data into features and target and drop irrelevant date field and target field\n",
    "X = data.drop(columns=[\"date\", \"demand\"])\n",
    "y = data[\"demand\"]\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": 100,\n",
    "    \"max_depth\": 6,\n",
    "    \"min_samples_split\": 10,\n",
    "    \"min_samples_leaf\": 4,\n",
    "    \"bootstrap\": True,\n",
    "    \"oob_score\": False,\n",
    "    \"random_state\": 888,\n",
    "}\n",
    "\n",
    "# Train the RandomForestRegressor\n",
    "rf = RandomForestRegressor(**params)\n",
    "\n",
    "# Fit the model on the training data\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred = rf.predict(X_val)\n",
    "\n",
    "# Calculate error metrics\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "# Assemble the metrics we're going to write into a collection\n",
    "metrics = {\"mae\": mae, \"mse\": mse, \"rmse\": rmse, \"r2\": r2}\n",
    "\n",
    "# Initiate the MLflow run context\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    # Log the parameters used for the model fit\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Log the error metrics that were calculated during validation\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    # Log an instance of the trained model for later use\n",
    "    mlflow.sklearn.log_model(sk_model=rf, input_example=X_val, artifact_path=artifact_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c06abe",
   "metadata": {},
   "source": [
    "#### Success!\n",
    "\n",
    "You've just logged your first MLflow model! \n",
    "\n",
    "Navigate to the MLflow UI to see the run that was just created (named \"apples_rf_test\", logged to the Experiment \"Apple_Models\"). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "54c88ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/11/16 10:26:02 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2023/11/16 10:26:02 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'cdfae31843f04bab88271c1a08568d85', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "mlflow.autolog()\n",
    "\n",
    "db = load_diabetes()\n",
    "X_train, X_test, y_train, y_test = train_test_split(db.data, db.target)\n",
    "\n",
    "# Create and train models.\n",
    "rf = RandomForestRegressor(n_estimators=100, max_depth=6, max_features=3)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Use the model to make predictions on the test dataset.\n",
    "predictions = rf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be60468",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
