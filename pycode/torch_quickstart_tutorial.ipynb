{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For tips on running notebooks in Google Colab, see\n",
    "# https://pytorch.org/tutorials/beginner/colab\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[Learn the Basics](intro.html) ||\n",
    "**Quickstart** ||\n",
    "[Tensors](tensorqs_tutorial.html) ||\n",
    "[Datasets & DataLoaders](data_tutorial.html) ||\n",
    "[Transforms](transforms_tutorial.html) ||\n",
    "[Build Model](buildmodel_tutorial.html) ||\n",
    "[Autograd](autogradqs_tutorial.html) ||\n",
    "[Optimization](optimization_tutorial.html) ||\n",
    "[Save & Load Model](saveloadrun_tutorial.html)\n",
    "\n",
    "# Quickstart\n",
    "This section runs through the API for common tasks in machine learning. Refer to the links in each section to dive deeper.\n",
    "\n",
    "## Working with data\n",
    "PyTorch has two [primitives to work with data](https://pytorch.org/docs/stable/data.html):\n",
    "``torch.utils.data.DataLoader`` and ``torch.utils.data.Dataset``.\n",
    "``Dataset`` stores the samples and their corresponding labels, and ``DataLoader`` wraps an iterable around\n",
    "the ``Dataset``.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch offers domain-specific libraries such as [TorchText](https://pytorch.org/text/stable/index.html),\n",
    "[TorchVision](https://pytorch.org/vision/stable/index.html), and [TorchAudio](https://pytorch.org/audio/stable/index.html),\n",
    "all of which include datasets. For this tutorial, we  will be using a TorchVision dataset.\n",
    "\n",
    "The ``torchvision.datasets`` module contains ``Dataset`` objects for many real-world vision data like\n",
    "CIFAR, COCO ([full list here](https://pytorch.org/vision/stable/datasets.html)). In this tutorial, we\n",
    "use the FashionMNIST dataset. Every TorchVision ``Dataset`` includes two arguments: ``transform`` and\n",
    "``target_transform`` to modify the samples and labels respectively.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pass the ``Dataset`` as an argument to ``DataLoader``. This wraps an iterable over our dataset, and supports\n",
    "automatic batching, sampling, shuffling and multiprocess data loading. Here we define a batch size of 64, i.e. each element\n",
    "in the dataloader iterable will return a batch of 64 features and labels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read more about [loading data in PyTorch](data_tutorial.html).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method create_experiment in module mlflow.tracking.client:\n",
      "\n",
      "create_experiment(name: str, artifact_location: Optional[str] = None, tags: Optional[Dict[str, Any]] = None) -> str method of mlflow.tracking.client.MlflowClient instance\n",
      "    Create an experiment.\n",
      "    \n",
      "    :param name: The experiment name. Must be unique.\n",
      "    :param artifact_location: The location to store run artifacts.\n",
      "                              If not provided, the server picks an appropriate default.\n",
      "    :param tags: A dictionary of key-value pairs that are converted into\n",
      "                            :py:class:`mlflow.entities.ExperimentTag` objects, set as\n",
      "                            experiment tags upon experiment creation.\n",
      "    :return: String as an integer ID of the created experiment.\n",
      "    \n",
      "    .. code-block:: python\n",
      "        :caption: Example\n",
      "    \n",
      "        from pathlib import Path\n",
      "        from mlflow import MlflowClient\n",
      "    \n",
      "        # Create an experiment with a name that is unique and case sensitive.\n",
      "        client = MlflowClient()\n",
      "        experiment_id = client.create_experiment(\n",
      "            \"Social NLP Experiments\",\n",
      "            artifact_location=Path.cwd().joinpath(\"mlruns\").as_uri(),\n",
      "            tags={\"version\": \"v1\", \"priority\": \"P1\"},\n",
      "        )\n",
      "        client.set_experiment_tag(experiment_id, \"nlp.framework\", \"Spark NLP\")\n",
      "    \n",
      "        # Fetch experiment metadata information\n",
      "        experiment = client.get_experiment(experiment_id)\n",
      "        print(\"Name: {}\".format(experiment.name))\n",
      "        print(\"Experiment_id: {}\".format(experiment.experiment_id))\n",
      "        print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
      "        print(\"Tags: {}\".format(experiment.tags))\n",
      "        print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\n",
      "    \n",
      "    .. code-block:: text\n",
      "        :caption: Output\n",
      "    \n",
      "        Name: Social NLP Experiments\n",
      "        Experiment_id: 1\n",
      "        Artifact Location: file:///.../mlruns\n",
      "        Tags: {'version': 'v1', 'priority': 'P1', 'nlp.framework': 'Spark NLP'}\n",
      "        Lifecycle_stage: active\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(mlflow.MlflowClient().create_experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = mlflow.MlflowClient(tracking_uri=\"http://127.0.0.1:5000\")\n",
    "# experiment_description = (\n",
    "#     \"This is the tutorial of pytorch. \"\n",
    "# )\n",
    "\n",
    "# experiment_tags = {\n",
    "#     \"project_name\": \"Fashion_MNIST\",\n",
    "#     \"mlflow.note.content\": experiment_description,\n",
    "# }\n",
    "\n",
    "# MNIST_experiment = client.create_experiment(name=\"DNN\", tags=experiment_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets the current active experiment to the \"Apple_Models\" experiment and returns the Experiment metadata\n",
    "apple_experiment = mlflow.set_experiment(\"DNN\")\n",
    "\n",
    "# Define a run name for this iteration of training.\n",
    "# If this is not set, a unique name will be auto-generated for your run.\n",
    "run_name = \"MNIST_test\"\n",
    "\n",
    "# Define an artifact path that the model will be saved to.\n",
    "artifact_path = \"MNIST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mlflow.pytorch.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function autolog in module mlflow.pytorch:\n",
      "\n",
      "autolog(log_every_n_epoch=1, log_every_n_step=None, log_models=True, log_datasets=True, disable=False, exclusive=False, disable_for_unsupported_versions=False, silent=False, registered_model_name=None, extra_tags=None)\n",
      "    .. Note:: Autologging is known to be compatible with the following package versions: ``1.6.0`` <= ``torch`` <= ``2.0.1``. Autologging may not succeed when used with package versions outside of this range.\n",
      "    \n",
      "    \n",
      "    Enables (or disables) and configures autologging from `PyTorch Lightning\n",
      "    <https://pytorch-lightning.readthedocs.io/en/latest>`_ to MLflow.\n",
      "    \n",
      "    Autologging is performed when you call the `fit` method of\n",
      "    `pytorch_lightning.Trainer()     <https://pytorch-lightning.readthedocs.io/en/latest/trainer.html#>`_.\n",
      "    \n",
      "    Explore the complete `PyTorch MNIST     <https://github.com/mlflow/mlflow/tree/master/examples/pytorch/MNIST>`_ for\n",
      "    an expansive example with implementation of additional lightening steps.\n",
      "    \n",
      "    **Note**: Full autologging is only supported for PyTorch Lightning models,\n",
      "    i.e., models that subclass\n",
      "    `pytorch_lightning.LightningModule     <https://pytorch-lightning.readthedocs.io/en/latest/lightning_module.html>`_.\n",
      "    Autologging support for vanilla PyTorch (ie models that only subclass\n",
      "    `torch.nn.Module <https://pytorch.org/docs/stable/generated/torch.nn.Module.html>`_)\n",
      "    only autologs calls to\n",
      "    `torch.utils.tensorboard.SummaryWriter <https://pytorch.org/docs/stable/tensorboard.html>`_'s\n",
      "    ``add_scalar`` and ``add_hparams`` methods to mlflow. In this case, there's also\n",
      "    no notion of an \"epoch\".\n",
      "    \n",
      "    .. Note:: Only pytorch-lightning modules between versions 1.0.5 and\n",
      "              2.0.6 are known to be compatible with mlflow's autologging.\n",
      "    \n",
      "    :param log_every_n_epoch: If specified, logs metrics once every `n` epochs. By default, metrics\n",
      "                       are logged after every epoch.\n",
      "    :param log_every_n_step: If specified, logs batch metrics once every `n` global step.\n",
      "                       By default, metrics are not logged for steps. Note that setting this to 1 can\n",
      "                       cause performance issues and is not recommended.\n",
      "    :param log_models: If ``True``, trained models are logged as MLflow model artifacts.\n",
      "                       If ``False``, trained models are not logged.\n",
      "    :param log_datasets: If ``True``, dataset information is logged to MLflow Tracking.\n",
      "                         If ``False``, dataset information is not logged.\n",
      "    :param disable: If ``True``, disables the PyTorch Lightning autologging integration.\n",
      "                    If ``False``, enables the PyTorch Lightning autologging integration.\n",
      "    :param exclusive: If ``True``, autologged content is not logged to user-created fluent runs.\n",
      "                      If ``False``, autologged content is logged to the active fluent run,\n",
      "                      which may be user-created.\n",
      "    :param disable_for_unsupported_versions: If ``True``, disable autologging for versions of\n",
      "                      pytorch and pytorch-lightning that have not been tested against this version\n",
      "                      of the MLflow client or are incompatible.\n",
      "    :param silent: If ``True``, suppress all event logs and warnings from MLflow during PyTorch\n",
      "                   Lightning autologging. If ``False``, show all events and warnings during\n",
      "                   PyTorch Lightning autologging.\n",
      "    :param registered_model_name: If given, each time a model is trained, it is registered as a\n",
      "                                  new model version of the registered model with this name.\n",
      "                                  The registered model is created if it does not already exist.\n",
      "    :param extra_tags: A dictionary of extra tags to set on each managed run created by autologging.\n",
      "    \n",
      "    .. code-block:: python\n",
      "        :caption: Example\n",
      "    \n",
      "        import os\n",
      "    \n",
      "        import pytorch_lightning as pl\n",
      "        import torch\n",
      "        from torch.nn import functional as F\n",
      "        from torch.utils.data import DataLoader\n",
      "        from torchvision import transforms\n",
      "        from torchvision.datasets import MNIST\n",
      "    \n",
      "        try:\n",
      "            from torchmetrics.functional import accuracy\n",
      "        except ImportError:\n",
      "            from pytorch_lightning.metrics.functional import accuracy\n",
      "    \n",
      "        import mlflow.pytorch\n",
      "        from mlflow import MlflowClient\n",
      "    \n",
      "        # For brevity, here is the simplest most minimal example with just a training\n",
      "        # loop step, (no validation, no testing). It illustrates how you can use MLflow\n",
      "        # to auto log parameters, metrics, and models.\n",
      "    \n",
      "    \n",
      "        class MNISTModel(pl.LightningModule):\n",
      "            def __init__(self):\n",
      "                super().__init__()\n",
      "                self.l1 = torch.nn.Linear(28 * 28, 10)\n",
      "    \n",
      "            def forward(self, x):\n",
      "                return torch.relu(self.l1(x.view(x.size(0), -1)))\n",
      "    \n",
      "            def training_step(self, batch, batch_nb):\n",
      "                x, y = batch\n",
      "                logits = self(x)\n",
      "                loss = F.cross_entropy(logits, y)\n",
      "                pred = logits.argmax(dim=1)\n",
      "                acc = accuracy(pred, y)\n",
      "    \n",
      "                # Use the current of PyTorch logger\n",
      "                self.log(\"train_loss\", loss, on_epoch=True)\n",
      "                self.log(\"acc\", acc, on_epoch=True)\n",
      "                return loss\n",
      "    \n",
      "            def configure_optimizers(self):\n",
      "                return torch.optim.Adam(self.parameters(), lr=0.02)\n",
      "    \n",
      "    \n",
      "        def print_auto_logged_info(r):\n",
      "            tags = {k: v for k, v in r.data.tags.items() if not k.startswith(\"mlflow.\")}\n",
      "            artifacts = [f.path for f in MlflowClient().list_artifacts(r.info.run_id, \"model\")]\n",
      "            print(\"run_id: {}\".format(r.info.run_id))\n",
      "            print(\"artifacts: {}\".format(artifacts))\n",
      "            print(\"params: {}\".format(r.data.params))\n",
      "            print(\"metrics: {}\".format(r.data.metrics))\n",
      "            print(\"tags: {}\".format(tags))\n",
      "    \n",
      "    \n",
      "        # Initialize our model\n",
      "        mnist_model = MNISTModel()\n",
      "    \n",
      "        # Initialize DataLoader from MNIST Dataset\n",
      "        train_ds = MNIST(\n",
      "            os.getcwd(), train=True, download=True, transform=transforms.ToTensor()\n",
      "        )\n",
      "        train_loader = DataLoader(train_ds, batch_size=32)\n",
      "    \n",
      "        # Initialize a trainer\n",
      "        trainer = pl.Trainer(max_epochs=20, progress_bar_refresh_rate=20)\n",
      "    \n",
      "        # Auto log all MLflow entities\n",
      "        mlflow.pytorch.autolog()\n",
      "    \n",
      "        # Train the model\n",
      "        with mlflow.start_run() as run:\n",
      "            trainer.fit(mnist_model, train_loader)\n",
      "    \n",
      "        # fetch the auto logged parameters and metrics\n",
      "        print_auto_logged_info(mlflow.get_run(run_id=run.info.run_id))\n",
      "    \n",
      "    .. code-block:: text\n",
      "        :caption: Output\n",
      "    \n",
      "        run_id: 42caa17b60cb489c8083900fb52506a7\n",
      "        artifacts: ['model/MLmodel', 'model/conda.yaml', 'model/data']\n",
      "        params: {'betas': '(0.9, 0.999)',\n",
      "                 'weight_decay': '0',\n",
      "                 'epochs': '20',\n",
      "                 'eps': '1e-08',\n",
      "                 'lr': '0.02',\n",
      "                 'optimizer_name': 'Adam', '\n",
      "                 amsgrad': 'False'}\n",
      "        metrics: {'acc_step': 0.0,\n",
      "                  'train_loss_epoch': 1.0917967557907104,\n",
      "                  'train_loss_step': 1.0794280767440796,\n",
      "                  'train_loss': 1.0794280767440796,\n",
      "                  'acc_epoch': 0.0033333334140479565,\n",
      "                  'acc': 0.0}\n",
      "        tags: {'Mode': 'training'}\n",
      "    \n",
      "    .. figure:: ../_static/images/pytorch_lightening_autolog.png\n",
      "    \n",
      "        PyTorch autologged MLflow entities\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(mlflow.pytorch.autolog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Models\n",
    "To define a neural network in PyTorch, we create a class that inherits\n",
    "from [nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html). We define the layers of the network\n",
    "in the ``__init__`` function and specify how data will pass through the network in the ``forward`` function. To accelerate\n",
    "operations in the neural network, we move it to the GPU or MPS if available.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import lightning as L\n",
    "import torch\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor, ModelCheckpoint\n",
    "from lightning.pytorch.cli import LightningCLI\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchmetrics.functional import accuracy\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import mlflow.pytorch\n",
    "\n",
    "class LightningMNISTClassifier(L.LightningModule):\n",
    "    def __init__(self, learning_rate=0.01):\n",
    "        \"\"\"\n",
    "        Initializes the network\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # mnist images are (1, 28, 28) (channels, width, height)\n",
    "        self.optimizer = None\n",
    "        self.scheduler = None\n",
    "        self.layer_1 = torch.nn.Linear(28 * 28, 512)\n",
    "        self.layer_2 = torch.nn.Linear(512, 512)\n",
    "        self.layer_3 = torch.nn.Linear(512, 10)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.val_outputs = []\n",
    "        self.test_outputs = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: Input data\n",
    "\n",
    "        :return: output - mnist digit label for the input image\n",
    "        \"\"\"\n",
    "        batch_size = x.size()[0]\n",
    "\n",
    "        # (b, 1, 28, 28) -> (b, 1*28*28)\n",
    "        x = x.view(batch_size, -1)\n",
    "\n",
    "        # layer 1 (b, 1*28*28) -> (b, 512)\n",
    "        x = self.layer_1(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        # layer 2 (b, 512) -> (b, 512)\n",
    "        x = self.layer_2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        # layer 3 (b, 512) -> (b, 10)\n",
    "        x = self.layer_3(x)\n",
    "\n",
    "        # probability distribution over labels\n",
    "        x = torch.log_softmax(x, dim=1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def cross_entropy_loss(self, logits, labels):\n",
    "        \"\"\"\n",
    "        Initializes the loss function\n",
    "\n",
    "        :return: output - Initialized cross entropy loss function\n",
    "        \"\"\"\n",
    "        return F.nll_loss(logits, labels)\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Training the data as batches and returns training loss on each batch\n",
    "\n",
    "        :param train_batch: Batch data\n",
    "        :param batch_idx: Batch indices\n",
    "\n",
    "        :return: output - Training loss\n",
    "        \"\"\"\n",
    "        x, y = train_batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.cross_entropy_loss(logits, y)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Performs validation of data in batches\n",
    "\n",
    "        :param val_batch: Batch data\n",
    "        :param batch_idx: Batch indices\n",
    "\n",
    "        :return: output - valid step loss\n",
    "        \"\"\"\n",
    "        x, y = val_batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.cross_entropy_loss(logits, y)\n",
    "        self.val_outputs.append(loss)\n",
    "        return {\"val_step_loss\": loss}\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        \"\"\"\n",
    "        Computes average validation loss\n",
    "        \"\"\"\n",
    "        avg_loss = torch.stack(self.val_outputs).mean()\n",
    "        self.log(\"val_loss\", avg_loss, sync_dist=True)\n",
    "        self.val_outputs.clear()\n",
    "\n",
    "    def test_step(self, test_batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Performs test and computes the accuracy of the model\n",
    "\n",
    "        :param test_batch: Batch data\n",
    "        :param batch_idx: Batch indices\n",
    "\n",
    "        :return: output - Testing accuracy\n",
    "        \"\"\"\n",
    "        x, y = test_batch\n",
    "        output = self.forward(x)\n",
    "        _, y_hat = torch.max(output, dim=1)\n",
    "        test_acc = accuracy(y_hat.cpu(), y.cpu(), task=\"multiclass\", num_classes=10)\n",
    "        self.test_outputs.append(test_acc)\n",
    "        return {\"test_acc\": test_acc}\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        \"\"\"\n",
    "        Computes average test accuracy score\n",
    "        \"\"\"\n",
    "        avg_test_acc = torch.stack(self.test_outputs).mean()\n",
    "        self.log(\"avg_test_acc\", avg_test_acc, sync_dist=True)\n",
    "        self.test_outputs.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"\n",
    "        Initializes the optimizer and learning rate scheduler\n",
    "\n",
    "        :return: output - Initialized optimizer and scheduler\n",
    "        \"\"\"\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        self.scheduler = {\n",
    "            \"scheduler\": torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                self.optimizer,\n",
    "                mode=\"min\",\n",
    "                factor=0.2,\n",
    "                patience=2,\n",
    "                min_lr=1e-6,\n",
    "                verbose=True,\n",
    "            ),\n",
    "            \"monitor\": \"val_loss\",\n",
    "        }\n",
    "        return [self.optimizer], [self.scheduler]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "class NNModule(pl.LightningModule):\n",
    "    def __init__(self, ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, imgs):\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "\n",
    "    def test_step(self, batch, batch_idx):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read more about [building neural networks in PyTorch](buildmodel_tutorial.html).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing the Model Parameters\n",
    "To train a model, we need a [loss function](https://pytorch.org/docs/stable/nn.html#loss-functions)\n",
    "and an [optimizer](https://pytorch.org/docs/stable/optim.html).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a single training loop, the model makes predictions on the training dataset (fed to it in batches), and\n",
    "backpropagates the prediction error to adjust the model's parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also check the model's performance against the test dataset to ensure it is learning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training process is conducted over several iterations (*epochs*). During each epoch, the model learns\n",
    "parameters to make better predictions. We print the model's accuracy and loss at each epoch; we'd like to see the\n",
    "accuracy increase and the loss decrease with every epoch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.301971  [   64/60000]\n",
      "loss: 2.291928  [ 6464/60000]\n",
      "loss: 2.269500  [12864/60000]\n",
      "loss: 2.263815  [19264/60000]\n",
      "loss: 2.256734  [25664/60000]\n",
      "loss: 2.227207  [32064/60000]\n",
      "loss: 2.231507  [38464/60000]\n",
      "loss: 2.199894  [44864/60000]\n",
      "loss: 2.191018  [51264/60000]\n",
      "loss: 2.166434  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 40.6%, Avg loss: 2.158883 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.169904  [   64/60000]\n",
      "loss: 2.160477  [ 6464/60000]\n",
      "loss: 2.103833  [12864/60000]\n",
      "loss: 2.113905  [19264/60000]\n",
      "loss: 2.073478  [25664/60000]\n",
      "loss: 2.019391  [32064/60000]\n",
      "loss: 2.036571  [38464/60000]\n",
      "loss: 1.963902  [44864/60000]\n",
      "loss: 1.957310  [51264/60000]\n",
      "loss: 1.895320  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 57.8%, Avg loss: 1.888790 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.928461  [   64/60000]\n",
      "loss: 1.893884  [ 6464/60000]\n",
      "loss: 1.778176  [12864/60000]\n",
      "loss: 1.807499  [19264/60000]\n",
      "loss: 1.709059  [25664/60000]\n",
      "loss: 1.665848  [32064/60000]\n",
      "loss: 1.679179  [38464/60000]\n",
      "loss: 1.584256  [44864/60000]\n",
      "loss: 1.600558  [51264/60000]\n",
      "loss: 1.496572  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 60.1%, Avg loss: 1.513966 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.590141  [   64/60000]\n",
      "loss: 1.547735  [ 6464/60000]\n",
      "loss: 1.400299  [12864/60000]\n",
      "loss: 1.462611  [19264/60000]\n",
      "loss: 1.349608  [25664/60000]\n",
      "loss: 1.347443  [32064/60000]\n",
      "loss: 1.355604  [38464/60000]\n",
      "loss: 1.287826  [44864/60000]\n",
      "loss: 1.316849  [51264/60000]\n",
      "loss: 1.212426  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.0%, Avg loss: 1.244654 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.327393  [   64/60000]\n",
      "loss: 1.304128  [ 6464/60000]\n",
      "loss: 1.144300  [12864/60000]\n",
      "loss: 1.241846  [19264/60000]\n",
      "loss: 1.118889  [25664/60000]\n",
      "loss: 1.147541  [32064/60000]\n",
      "loss: 1.161202  [38464/60000]\n",
      "loss: 1.109027  [44864/60000]\n",
      "loss: 1.140897  [51264/60000]\n",
      "loss: 1.052706  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.8%, Avg loss: 1.081193 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    #with mlflow.start_run() as run:\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read more about [Training your model](optimization_tutorial.html).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Models\n",
    "A common way to save a model is to serialize the internal state dictionary (containing the model parameters).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function save in module torch.serialization:\n",
      "\n",
      "save(obj: object, f: Union[str, os.PathLike, BinaryIO, IO[bytes]], pickle_module: Any = <module 'pickle' from '/home/jy_zhang/anaconda3/envs/pytorch/lib/python3.11/pickle.py'>, pickle_protocol: int = 2, _use_new_zipfile_serialization: bool = True, _disable_byteorder_record: bool = False) -> None\n",
      "    save(obj, f, pickle_module=pickle, pickle_protocol=DEFAULT_PROTOCOL, _use_new_zipfile_serialization=True)\n",
      "    \n",
      "    Saves an object to a disk file.\n",
      "    \n",
      "    See also: :ref:`saving-loading-tensors`\n",
      "    \n",
      "    Args:\n",
      "        obj: saved object\n",
      "        f: a file-like object (has to implement write and flush) or a string or\n",
      "           os.PathLike object containing a file name\n",
      "        pickle_module: module used for pickling metadata and objects\n",
      "        pickle_protocol: can be specified to override the default protocol\n",
      "    \n",
      "    .. note::\n",
      "        A common PyTorch convention is to save tensors using .pt file extension.\n",
      "    \n",
      "    .. note::\n",
      "        PyTorch preserves storage sharing across serialization. See\n",
      "        :ref:`preserve-storage-sharing` for more details.\n",
      "    \n",
      "    .. note::\n",
      "        The 1.6 release of PyTorch switched ``torch.save`` to use a new\n",
      "        zipfile-based file format. ``torch.load`` still retains the ability to\n",
      "        load files in the old format. If for any reason you want ``torch.save``\n",
      "        to use the old format, pass the kwarg ``_use_new_zipfile_serialization=False``.\n",
      "    \n",
      "    Example:\n",
      "        >>> # xdoctest: +SKIP(\"makes cwd dirty\")\n",
      "        >>> # Save to file\n",
      "        >>> x = torch.tensor([0, 1, 2, 3, 4])\n",
      "        >>> torch.save(x, 'tensor.pt')\n",
      "        >>> # Save to io.BytesIO buffer\n",
      "        >>> buffer = io.BytesIO()\n",
      "        >>> torch.save(x, buffer)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model2.pth\",_use_new_zipfile_serialization = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear_relu_stack.0.weight',\n",
       "              tensor([[ 0.0064,  0.0315, -0.0321,  ..., -0.0101,  0.0273,  0.0081],\n",
       "                      [ 0.0022,  0.0187, -0.0348,  ..., -0.0086,  0.0019,  0.0317],\n",
       "                      [-0.0080,  0.0343, -0.0164,  ...,  0.0348, -0.0317,  0.0242],\n",
       "                      ...,\n",
       "                      [-0.0227,  0.0337, -0.0025,  ..., -0.0222, -0.0263, -0.0269],\n",
       "                      [ 0.0132,  0.0280,  0.0144,  ..., -0.0317,  0.0196,  0.0077],\n",
       "                      [-0.0294,  0.0313, -0.0134,  ...,  0.0300, -0.0182, -0.0079]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_relu_stack.0.bias',\n",
       "              tensor([-1.9945e-02, -2.9500e-02,  1.6078e-02, -2.8489e-02, -7.7808e-04,\n",
       "                       1.2074e-02, -7.4671e-03, -2.6765e-02,  4.3378e-04,  2.8306e-02,\n",
       "                       1.8506e-02, -4.8354e-03,  4.3320e-03,  1.9686e-02,  1.8991e-02,\n",
       "                       1.4672e-02, -1.5688e-02, -2.6641e-02,  2.3393e-02,  1.4413e-02,\n",
       "                      -1.8620e-02,  2.3331e-02, -1.4143e-02,  2.4259e-02, -2.3977e-02,\n",
       "                       4.4651e-02,  3.1522e-02,  4.0013e-03,  2.5724e-03,  2.9434e-02,\n",
       "                      -2.7789e-02,  4.1712e-02,  4.4932e-02,  6.8262e-03,  1.8729e-02,\n",
       "                      -2.1861e-04, -3.3831e-02, -3.1516e-02,  2.8222e-02, -2.5910e-04,\n",
       "                      -1.9406e-02,  2.4990e-02,  3.3696e-02, -5.8811e-04,  2.5136e-02,\n",
       "                       3.7421e-02,  9.3637e-03, -2.1116e-03,  3.6836e-02, -1.5471e-03,\n",
       "                      -1.1620e-02,  1.6276e-02, -1.2655e-03,  8.1918e-03, -3.1077e-02,\n",
       "                      -3.7191e-02, -1.8531e-02, -6.8886e-03, -2.7712e-03, -3.1416e-02,\n",
       "                      -3.7363e-03,  1.5436e-02, -1.2370e-02, -1.1328e-02,  1.9799e-02,\n",
       "                       2.8754e-02,  1.8653e-02,  4.1417e-02,  2.5147e-03,  1.9729e-03,\n",
       "                       3.4796e-02,  2.4292e-02,  4.3443e-03, -2.1042e-02, -1.8313e-03,\n",
       "                       3.2762e-03, -3.0787e-02,  9.5508e-03, -1.3778e-04, -5.8417e-03,\n",
       "                       2.8698e-03,  2.7246e-02, -1.0270e-02,  4.3606e-02,  1.1083e-02,\n",
       "                       2.7115e-02, -5.8924e-03, -2.0769e-03,  2.2977e-02,  4.6437e-03,\n",
       "                      -3.5268e-02, -3.0741e-02, -2.9603e-02, -2.2509e-02,  2.4488e-02,\n",
       "                       2.4129e-02, -1.6978e-02, -1.3918e-02, -1.0393e-02, -1.1616e-02,\n",
       "                      -3.0861e-02,  6.5715e-03,  5.0152e-03, -2.9072e-02,  3.9476e-04,\n",
       "                      -3.4578e-04,  5.7589e-03,  3.8461e-03,  5.7779e-03,  2.8490e-02,\n",
       "                       2.9047e-02, -2.3591e-02, -8.5220e-03,  3.2264e-02,  3.2623e-03,\n",
       "                       4.5312e-03, -3.8277e-02,  5.6027e-03,  1.1673e-02, -2.2224e-02,\n",
       "                      -2.2473e-03,  4.8784e-03, -1.3796e-02,  5.7928e-03,  3.2934e-02,\n",
       "                      -9.6379e-03, -2.8049e-02, -2.8370e-02,  8.8861e-03,  1.7463e-02,\n",
       "                      -3.7251e-03, -3.9637e-02,  9.1245e-04,  3.4340e-02, -2.3568e-02,\n",
       "                       2.5865e-02,  2.9219e-02, -5.6504e-03,  2.2824e-02,  1.4308e-02,\n",
       "                       2.0537e-02, -2.9123e-02,  1.3758e-02,  2.7329e-02,  2.7690e-02,\n",
       "                       2.8263e-02, -7.9024e-03,  3.1993e-02, -1.8710e-02,  2.4708e-02,\n",
       "                      -6.7419e-03,  5.4820e-03, -7.5421e-03,  3.0300e-02, -2.1042e-02,\n",
       "                       1.4759e-02, -1.2651e-02, -1.7413e-02, -1.3838e-02, -2.8649e-03,\n",
       "                       1.3622e-02, -3.3284e-02, -3.7381e-03,  8.4756e-03,  2.9434e-02,\n",
       "                       9.9651e-04,  3.7536e-02, -2.8178e-02, -3.0153e-02, -8.9907e-03,\n",
       "                       3.3385e-02, -1.9534e-02, -1.6641e-02,  2.0255e-02,  6.7661e-03,\n",
       "                      -3.1836e-02,  8.0469e-03,  3.2432e-03, -4.7320e-05, -3.9662e-02,\n",
       "                       4.5284e-02, -3.2554e-02,  2.2281e-02, -2.7501e-02,  3.2374e-02,\n",
       "                       2.3047e-02,  6.0856e-02,  2.3548e-02, -9.4314e-03,  1.9311e-02,\n",
       "                      -3.2236e-02,  2.8214e-03, -3.0037e-02,  3.2019e-02,  9.6498e-03,\n",
       "                       1.8610e-02, -9.1533e-03, -3.1686e-02, -9.9067e-05,  2.8653e-02,\n",
       "                       5.6455e-03,  3.5717e-02, -1.8483e-02, -3.5022e-03, -1.2973e-03,\n",
       "                      -1.4075e-02,  4.6908e-03, -2.0297e-03, -7.2721e-03,  2.7043e-02,\n",
       "                      -2.1631e-02,  2.0149e-03, -2.3787e-02, -3.1505e-02, -1.1389e-04,\n",
       "                       1.4554e-02,  1.2563e-02, -2.5487e-02,  1.6325e-02, -2.1695e-02,\n",
       "                      -2.3108e-02,  4.0524e-02, -2.2492e-02, -2.8273e-03,  1.1719e-02,\n",
       "                      -3.3383e-04, -6.8433e-03, -3.1971e-02, -2.7147e-02,  1.6464e-02,\n",
       "                      -5.1192e-03, -1.4499e-02,  2.9448e-02,  1.0526e-03,  6.7057e-04,\n",
       "                       2.1209e-02, -7.5513e-03,  2.8567e-02,  2.2378e-02, -6.5507e-03,\n",
       "                       5.0449e-03, -1.3052e-02, -2.1711e-02,  2.6033e-02, -7.6132e-03,\n",
       "                       1.9570e-02,  4.2267e-02, -1.5315e-02, -1.2559e-02, -1.2059e-03,\n",
       "                       2.4026e-02, -1.6638e-02, -2.6067e-02,  1.6626e-02, -1.4787e-02,\n",
       "                       3.3457e-02,  3.4337e-02, -2.8670e-02, -7.1643e-03, -5.3435e-03,\n",
       "                       4.9417e-02,  2.3946e-02,  2.1979e-02, -2.5245e-02,  1.8740e-02,\n",
       "                      -1.6619e-03,  2.5117e-02,  5.4412e-03, -2.4553e-02, -3.0723e-04,\n",
       "                      -3.0136e-02,  9.5305e-03,  8.5126e-03,  8.7346e-03,  8.0121e-03,\n",
       "                      -1.9512e-02, -6.6482e-03, -1.4518e-02,  4.4488e-02, -3.2529e-03,\n",
       "                      -3.0592e-02, -1.1297e-02, -3.0775e-02, -3.3043e-02, -2.1260e-02,\n",
       "                       1.5498e-02, -2.0210e-02,  2.1945e-03,  6.3340e-03,  1.5720e-02,\n",
       "                      -2.6222e-04,  1.7527e-02, -2.0351e-03,  1.3587e-02,  4.5036e-04,\n",
       "                      -1.2332e-02, -1.4619e-02,  1.1840e-02, -3.5716e-02,  3.6851e-02,\n",
       "                      -2.6546e-02, -3.0110e-02,  1.8337e-02,  2.1065e-02, -2.3313e-02,\n",
       "                       2.4598e-02, -1.9491e-02, -3.0768e-03, -3.5248e-03, -5.4579e-03,\n",
       "                      -1.5275e-03,  2.7578e-02,  2.1078e-02,  1.0850e-02,  1.4306e-02,\n",
       "                       4.3522e-02,  4.1098e-02,  3.0223e-02,  2.8085e-02,  2.6668e-02,\n",
       "                       1.4247e-02, -3.2445e-02,  1.0180e-02, -1.9462e-02,  1.1571e-02,\n",
       "                       1.2492e-02,  1.1801e-02, -3.2400e-02, -2.0788e-02,  2.0787e-02,\n",
       "                       2.6083e-02, -7.4987e-03,  2.8717e-02, -2.1426e-02, -5.6652e-03,\n",
       "                      -3.6716e-02,  1.5410e-02, -1.0931e-02,  1.1163e-02,  3.0193e-02,\n",
       "                      -1.3505e-02, -2.5925e-03,  1.8131e-02,  3.1015e-02,  3.9166e-02,\n",
       "                      -2.5659e-02,  1.7912e-02,  9.4657e-03, -2.5307e-02, -1.3263e-03,\n",
       "                      -1.3132e-02, -2.7937e-02, -1.7774e-02,  2.3340e-02,  2.5499e-02,\n",
       "                      -3.0052e-02,  3.8122e-02, -3.3104e-02, -2.7405e-02,  1.9381e-02,\n",
       "                       2.2069e-03, -1.2897e-02, -9.1224e-03, -3.2182e-02, -2.5253e-03,\n",
       "                       2.4865e-02,  4.3336e-03,  1.2651e-02,  3.8430e-02,  1.7309e-02,\n",
       "                      -4.5321e-03,  1.0642e-02,  1.3178e-02, -2.1734e-02, -1.5265e-03,\n",
       "                       3.1787e-02, -1.2508e-03,  1.4436e-02,  2.5616e-02, -2.0690e-02,\n",
       "                      -3.3229e-02,  7.8691e-03,  3.4052e-02,  1.8391e-02,  2.8032e-02,\n",
       "                       1.1241e-02,  8.2823e-03, -2.2813e-02,  3.1509e-02, -4.7117e-03,\n",
       "                       2.9153e-02,  2.6937e-02,  2.4246e-03, -2.6824e-02, -1.5094e-02,\n",
       "                       2.9515e-03,  3.1840e-02,  2.2460e-02, -4.7239e-03,  1.6407e-02,\n",
       "                       2.2436e-02,  3.0796e-02, -3.2057e-02,  2.6629e-02, -1.4351e-03,\n",
       "                      -2.9804e-02, -9.6096e-03,  1.1118e-02,  2.8049e-02, -3.2409e-02,\n",
       "                       1.3867e-02, -3.6234e-02,  4.2077e-02,  2.4546e-02,  4.1546e-02,\n",
       "                       1.4912e-02,  3.2857e-02,  8.9737e-03,  1.2283e-02, -2.4852e-02,\n",
       "                       2.0378e-02, -1.4385e-03, -1.2926e-02,  2.0170e-02, -9.7998e-03,\n",
       "                       1.9543e-02,  3.1455e-02, -2.6440e-02,  7.7538e-03, -3.2529e-02,\n",
       "                       9.4252e-03,  1.0784e-03,  3.3327e-02, -3.2584e-02,  2.5921e-02,\n",
       "                      -1.9927e-02,  4.3295e-02,  6.7353e-03,  2.9782e-02, -6.3520e-03,\n",
       "                      -2.7521e-02, -1.1914e-02,  1.8156e-04,  2.1815e-02, -2.4744e-02,\n",
       "                       3.7380e-03,  2.6372e-02,  3.7985e-03, -1.3962e-03,  3.3580e-02,\n",
       "                       3.3225e-02, -2.6471e-02,  1.9575e-02, -7.2777e-03,  5.6061e-04,\n",
       "                       1.1363e-02,  2.1933e-04,  2.4196e-02,  4.0793e-02,  1.1490e-02,\n",
       "                       3.5414e-02,  3.4939e-02,  4.6480e-02,  1.8544e-02, -1.7836e-02,\n",
       "                      -1.8211e-02,  1.5840e-02,  2.8952e-04,  3.1390e-03, -2.4178e-02,\n",
       "                       2.4098e-02, -2.1694e-02,  1.7737e-02,  1.5628e-02,  1.8219e-02,\n",
       "                      -3.4040e-03,  3.4555e-02,  3.9573e-02,  2.1330e-02,  2.3147e-02,\n",
       "                       2.8253e-03, -1.7682e-02,  5.6140e-03,  2.0503e-02,  3.0577e-02,\n",
       "                      -1.6975e-02, -1.6791e-02, -6.8203e-03, -1.7275e-02,  4.1355e-02,\n",
       "                      -1.5027e-02,  3.5562e-02,  3.5248e-02,  2.8536e-02,  3.1518e-02,\n",
       "                      -1.9097e-02,  9.4351e-03, -9.2815e-03,  2.1482e-02, -1.7986e-02,\n",
       "                       2.1080e-02, -2.5646e-02,  2.1280e-02, -2.0902e-03,  3.0591e-02,\n",
       "                      -7.4243e-03,  2.2557e-02, -3.4182e-03,  1.5234e-02,  2.5122e-02,\n",
       "                      -6.9055e-03,  1.9063e-03], device='cuda:0')),\n",
       "             ('linear_relu_stack.2.weight',\n",
       "              tensor([[ 0.0249, -0.0394, -0.0020,  ...,  0.0092, -0.0327,  0.0123],\n",
       "                      [-0.0162, -0.0147, -0.0345,  ...,  0.0173,  0.0111, -0.0178],\n",
       "                      [-0.0333, -0.0144,  0.0302,  ...,  0.0294, -0.0360, -0.0179],\n",
       "                      ...,\n",
       "                      [-0.0357,  0.0168, -0.0230,  ..., -0.0058,  0.0078,  0.0046],\n",
       "                      [-0.0285, -0.0259, -0.0318,  ...,  0.0296,  0.0129,  0.0064],\n",
       "                      [ 0.0147,  0.0100,  0.0024,  ..., -0.0330, -0.0180,  0.0136]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_relu_stack.2.bias',\n",
       "              tensor([ 3.3614e-02,  4.4988e-02, -2.3216e-02,  4.2550e-02, -3.9340e-02,\n",
       "                       1.4729e-02, -1.1516e-02,  3.4219e-02, -2.3033e-02,  1.9479e-02,\n",
       "                       9.4499e-03, -4.7194e-03,  1.8398e-02, -4.0684e-02,  5.9115e-02,\n",
       "                       4.2377e-02,  7.3563e-03,  3.7950e-03, -3.5243e-02, -3.3741e-02,\n",
       "                      -3.3499e-02,  3.8470e-02,  1.9344e-02,  6.1730e-02, -2.4667e-02,\n",
       "                      -4.0255e-02,  5.3633e-02,  6.0594e-02, -5.1046e-03,  1.9772e-02,\n",
       "                       2.5142e-02,  1.5430e-02, -4.1766e-02,  4.2618e-02, -3.0001e-02,\n",
       "                       3.7503e-02,  3.1308e-03,  3.6336e-02,  2.6059e-02,  4.2493e-02,\n",
       "                      -2.0255e-02, -1.1734e-02, -2.8555e-02,  4.9500e-02,  1.7284e-02,\n",
       "                      -2.6191e-02, -9.8794e-03,  3.3678e-02,  1.3978e-02, -3.9044e-02,\n",
       "                       5.2299e-02,  4.9212e-02,  1.6269e-02,  5.2048e-02, -2.8427e-02,\n",
       "                       1.1092e-02,  3.8886e-02, -1.7674e-02,  3.6395e-03,  4.6890e-02,\n",
       "                       1.6040e-02, -1.8481e-02,  3.9083e-02,  4.8367e-03, -8.6960e-03,\n",
       "                      -4.3847e-02,  1.6949e-02,  3.7590e-04,  9.8117e-03,  3.7073e-03,\n",
       "                      -4.3224e-03, -2.6973e-02, -6.8927e-03, -4.3688e-02,  3.1481e-02,\n",
       "                      -2.5199e-02,  1.8501e-02,  3.1048e-02,  3.9570e-03, -1.8424e-02,\n",
       "                      -4.0604e-02,  2.3951e-02, -4.1799e-02,  6.2546e-02, -3.4081e-02,\n",
       "                       3.9929e-02,  2.9589e-02,  4.6560e-02, -4.9067e-03,  8.8983e-03,\n",
       "                      -4.9280e-02,  1.7590e-02, -2.1005e-02, -1.3930e-03,  5.4782e-02,\n",
       "                       3.7313e-02,  2.5393e-02, -3.0371e-02,  5.7395e-02, -1.1851e-02,\n",
       "                       3.2505e-02, -3.5625e-03,  2.9267e-02,  5.5019e-02,  1.9995e-02,\n",
       "                       1.8353e-02, -6.7872e-03,  6.3048e-03,  2.1676e-02, -2.6511e-02,\n",
       "                      -1.4010e-02,  5.0281e-02, -4.6074e-02,  4.1555e-02, -2.4059e-02,\n",
       "                       3.3721e-02,  5.2737e-02,  1.1179e-02, -2.9515e-02, -5.8290e-03,\n",
       "                       6.4389e-03,  2.6244e-02, -4.8885e-02,  2.7160e-02,  2.2930e-02,\n",
       "                       2.6705e-02,  1.5779e-02,  7.5246e-03, -3.8891e-03,  1.2589e-02,\n",
       "                       7.8030e-03,  2.2590e-02, -2.9460e-02,  2.4195e-02, -3.2152e-02,\n",
       "                       3.0524e-02, -1.1495e-02,  1.7396e-02,  5.3253e-02,  4.9451e-02,\n",
       "                       4.7420e-02,  9.6050e-03,  7.5420e-03,  3.1468e-03, -9.1670e-03,\n",
       "                      -4.2068e-02, -2.8710e-03, -3.7961e-02,  3.6294e-02, -3.7139e-02,\n",
       "                       1.9049e-02, -3.3411e-02,  1.9884e-02, -9.1310e-03,  1.8700e-02,\n",
       "                       4.5404e-02,  8.0041e-03, -4.6501e-02,  4.9476e-02, -2.6313e-02,\n",
       "                      -3.9654e-03,  1.0964e-02,  2.6346e-02, -2.6986e-02,  2.0448e-02,\n",
       "                       1.0860e-02,  3.7444e-03,  4.3866e-02,  2.4975e-02,  4.7034e-02,\n",
       "                      -3.6644e-02,  4.2841e-02, -5.5525e-03,  1.5295e-02,  4.8605e-02,\n",
       "                       3.5401e-02, -1.5834e-02,  4.7272e-02, -1.8021e-02, -2.9551e-02,\n",
       "                       3.1682e-02,  1.3117e-02, -1.4081e-02,  4.7527e-02,  3.3175e-02,\n",
       "                       3.5737e-02,  3.9879e-02, -3.3939e-02,  4.5781e-02,  3.4372e-02,\n",
       "                      -1.7504e-02,  2.9141e-02,  4.2397e-02, -2.3797e-02, -1.4126e-02,\n",
       "                       1.5498e-03, -4.6210e-02,  1.5756e-02, -4.2438e-02,  4.0780e-02,\n",
       "                      -4.1291e-03,  7.4279e-03,  3.5723e-02, -1.7399e-02,  4.2445e-05,\n",
       "                       4.3955e-02,  3.0099e-02, -2.0530e-02, -1.5550e-02, -1.7965e-02,\n",
       "                      -3.2402e-02, -7.6108e-04,  2.0080e-02, -8.3106e-03,  4.7006e-02,\n",
       "                       1.3797e-02,  1.7385e-02, -1.0977e-02, -8.4625e-03, -4.0654e-02,\n",
       "                      -1.7760e-03, -3.9987e-02, -3.1314e-02, -1.9354e-02, -6.2081e-02,\n",
       "                      -2.5245e-02, -1.2721e-02,  3.9958e-02,  1.7167e-02,  3.4479e-02,\n",
       "                      -3.1133e-02,  2.9915e-02, -5.2510e-02,  6.4742e-03,  1.4870e-02,\n",
       "                       5.4489e-02, -2.7650e-02,  4.3486e-02,  3.3194e-02,  1.9733e-02,\n",
       "                      -2.0188e-02, -4.9053e-02, -1.1769e-02, -4.4557e-02, -3.1402e-02,\n",
       "                      -2.8629e-02, -5.8942e-03,  2.0122e-02,  5.3605e-03, -2.7220e-04,\n",
       "                       3.7660e-02,  1.1378e-02, -3.5411e-02, -1.3948e-02,  1.8109e-03,\n",
       "                       5.7897e-02, -1.9610e-02, -5.2644e-03, -4.1460e-02, -1.0667e-02,\n",
       "                       2.7279e-02,  4.8968e-03,  4.0528e-02,  3.8298e-02, -1.4049e-02,\n",
       "                       3.8207e-02, -1.0695e-02, -6.2646e-03,  2.7925e-02,  6.3015e-03,\n",
       "                      -1.1085e-02, -1.3555e-02,  1.6635e-02, -1.2923e-02,  3.5505e-02,\n",
       "                      -4.0632e-03, -1.2748e-02,  2.2220e-02, -4.5382e-02,  6.1783e-02,\n",
       "                       1.0861e-02,  3.9645e-02,  3.7515e-03,  8.3403e-03,  2.9679e-02,\n",
       "                      -9.5424e-03, -6.7811e-03,  2.2665e-03,  4.2692e-02, -1.2580e-03,\n",
       "                       6.8804e-03,  5.5513e-02, -1.4498e-02,  4.3430e-02,  4.1496e-02,\n",
       "                      -3.8469e-02, -2.2952e-02, -1.3530e-02, -2.7049e-02,  6.0971e-03,\n",
       "                       3.4320e-02,  7.1712e-03,  9.2736e-03,  6.1924e-03,  2.8801e-02,\n",
       "                      -2.7212e-02,  2.3120e-02, -8.7642e-04,  2.9048e-02,  6.5989e-03,\n",
       "                       7.0054e-02,  2.4703e-02,  2.3462e-02, -2.6346e-02,  3.4896e-02,\n",
       "                      -1.8475e-03,  1.7143e-02,  4.9625e-02, -2.2588e-02,  1.4966e-03,\n",
       "                       1.9847e-02,  5.5248e-02,  1.0870e-03,  2.6525e-02,  5.3943e-03,\n",
       "                      -3.4570e-02, -2.5982e-02, -2.7298e-02, -4.1399e-02, -2.0367e-02,\n",
       "                      -4.0223e-02,  2.5349e-02,  9.2658e-03,  4.6557e-02,  1.6515e-02,\n",
       "                       2.2480e-03,  4.7913e-02, -3.1960e-02, -1.6232e-02, -2.9033e-02,\n",
       "                       2.4835e-02, -4.2702e-02,  4.8246e-02,  1.8260e-02, -2.6147e-02,\n",
       "                       5.1373e-02,  1.8550e-02,  4.5857e-02, -1.0586e-02, -6.2692e-03,\n",
       "                      -4.1231e-02, -3.5261e-02,  4.0562e-02, -1.0120e-02,  2.5542e-02,\n",
       "                      -3.1086e-02,  3.0723e-02, -1.7941e-02,  5.9006e-02,  1.4868e-02,\n",
       "                       3.0711e-02,  3.4678e-02,  6.2911e-02,  7.2550e-03, -1.3119e-02,\n",
       "                       1.5796e-02,  2.3505e-03, -3.4189e-02,  6.5277e-03, -1.9676e-02,\n",
       "                      -3.3209e-02,  6.8262e-02, -3.3750e-03,  1.8997e-03, -2.3599e-02,\n",
       "                       3.7332e-02, -8.0700e-03, -3.6986e-02, -4.0310e-02, -4.1477e-02,\n",
       "                      -6.2025e-03,  3.8775e-02,  1.2296e-02, -7.2607e-03,  6.9470e-03,\n",
       "                       4.3654e-02, -4.2519e-02, -3.3477e-02, -1.8125e-02, -3.5865e-02,\n",
       "                       2.1326e-02, -3.6683e-02, -2.9579e-02, -6.6462e-03, -3.2990e-02,\n",
       "                       1.2132e-02, -3.3422e-02,  8.2821e-03,  7.4625e-03,  3.0295e-03,\n",
       "                      -2.4131e-02, -2.3430e-02, -7.5800e-03, -1.7379e-02, -1.7501e-02,\n",
       "                       2.7767e-02, -9.6331e-03, -1.9352e-02, -3.1443e-02, -5.9814e-03,\n",
       "                       2.7504e-02, -3.0859e-02, -1.0703e-02, -1.5734e-02,  2.5150e-02,\n",
       "                       1.7564e-02,  3.6354e-02, -5.6293e-03,  5.7934e-02,  2.7748e-02,\n",
       "                      -3.0444e-02, -1.0655e-02,  1.5842e-02,  3.0888e-02,  1.8167e-04,\n",
       "                       9.2222e-03, -4.1100e-02,  8.0921e-03,  9.1407e-03,  9.2859e-03,\n",
       "                      -1.9798e-02,  1.9418e-02, -3.0825e-02, -3.1984e-02, -5.7659e-03,\n",
       "                       2.7150e-04, -3.9554e-02,  3.8939e-02,  1.7694e-02,  4.2952e-02,\n",
       "                       3.0399e-02, -4.2330e-02, -2.2948e-02,  3.7469e-02,  2.4962e-02,\n",
       "                      -4.2983e-02, -2.2057e-02, -2.0128e-02,  1.9328e-02, -1.5277e-02,\n",
       "                      -1.6536e-02, -1.6903e-02,  2.2384e-02,  5.0890e-02,  3.2718e-02,\n",
       "                      -3.3185e-02, -3.6803e-02, -1.9574e-02,  2.6117e-02, -1.6724e-02,\n",
       "                      -1.7270e-02,  2.3276e-02,  2.9339e-02, -4.4908e-02,  9.6765e-03,\n",
       "                       4.6787e-02,  5.6724e-02, -2.0750e-02,  2.0850e-02,  3.1650e-02,\n",
       "                      -2.9317e-03,  4.1721e-02,  4.1014e-02,  3.7455e-02, -4.1844e-02,\n",
       "                       1.1346e-02,  4.0292e-03, -1.7385e-02,  4.5090e-02, -3.4949e-03,\n",
       "                       4.0830e-02, -2.7725e-02,  4.2207e-02, -1.6548e-03,  2.0133e-02,\n",
       "                       2.9737e-02, -1.9086e-02, -3.1090e-02, -5.5966e-02,  2.2817e-02,\n",
       "                      -2.3120e-02,  6.3650e-02, -2.2878e-02,  3.1639e-02,  4.3709e-02,\n",
       "                       1.8709e-02,  1.9852e-02,  3.1705e-02,  2.9889e-02, -6.8589e-03,\n",
       "                      -3.3920e-02,  4.5306e-02,  2.9583e-03,  3.1472e-02, -2.6796e-02,\n",
       "                       1.8724e-02, -3.1099e-02, -2.1351e-02, -4.3432e-02,  2.2291e-03,\n",
       "                       2.9900e-02,  2.7707e-03], device='cuda:0')),\n",
       "             ('linear_relu_stack.4.weight',\n",
       "              tensor([[ 0.0360,  0.0550,  0.0238,  ...,  0.0392, -0.0634, -0.0204],\n",
       "                      [ 0.0458, -0.0478, -0.0396,  ...,  0.0107, -0.0506, -0.0738],\n",
       "                      [ 0.0730,  0.0506, -0.0384,  ...,  0.0593,  0.0003, -0.0080],\n",
       "                      ...,\n",
       "                      [-0.1181, -0.0756,  0.0340,  ..., -0.0721, -0.0223, -0.0256],\n",
       "                      [-0.0273,  0.0077, -0.0070,  ...,  0.0592,  0.0123, -0.0019],\n",
       "                      [-0.0992,  0.0531,  0.0188,  ...,  0.0390,  0.0915,  0.0227]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_relu_stack.4.bias',\n",
       "              tensor([ 0.0157, -0.0071, -0.0701,  0.0303, -0.0660,  0.2710,  0.0016,  0.0885,\n",
       "                      -0.1199, -0.0806], device='cuda:0'))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.load(\"model.pth\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119547037146038801333356"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "f = open('model2.pth','rb')\n",
    "data = pickle.load(f)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Models\n",
    "\n",
    "The process for loading a model includes re-creating the model structure and loading\n",
    "the state dictionary into it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model can now be used to make predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read more about [Saving & Loading your model](saveloadrun_tutorial.html).\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
